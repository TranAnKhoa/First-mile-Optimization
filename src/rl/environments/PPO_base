import gymnasium as gym
from gymnasium import spaces
import numpy as np
import copy
import math
import random
from deap import base, creator, tools
import os
import sys
from deap import base, creator, tools, algorithms
# ==============================================================================
# [FIX QUAN TR·ªåNG]: TH√äM ƒê∆Ø·ªúNG D·∫™N 'src' V√ÄO H·ªÜ TH·ªêNG
# ==============================================================================
# L·∫•y ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a file n√†y (src/rl/environments)
current_dir = os.path.dirname(os.path.abspath(__file__))
# L√πi l·∫°i 2 c·∫•p ƒë·ªÉ l·∫•y th∆∞ m·ª•c 'src' (C:\AnKhoa\Project_Code\src)
src_path = os.path.abspath(os.path.join(current_dir, '..', '..'))

if src_path not in sys.path:
    sys.path.insert(0, src_path)
# ==============================================================================

# ==============================================================================
# IMPORT MODULE ALNS (ƒê√£ s·ª≠a l·∫°i ƒë·ªÉ ch·∫Øc ch·∫Øn t√¨m th·∫•y)
# ==============================================================================
try:
    # Th·ª≠ import tr·ª±c ti·∫øp t·ª´ routing (n·∫øu src ƒë√£ c√≥ trong path)
    from routing.cvrp.alns_cvrp.cvrp_env import cvrpEnv
    from routing.cvrp.alns_cvrp.initial_solution import compute_initial_solution
    
    # Import Operators
    from routing.cvrp.alns_cvrp.destroy_operators import (
        random_removal, worst_removal_alpha_0, worst_removal_bigM, 
        worst_removal_adaptive, time_worst_removal, shaw_spatial, 
        shaw_hybrid, shaw_temporal, shaw_structural, trip_removal, 
        historical_removal,update_solution_state_after_destroy, infeasible_constraint_removal
    )
    
    from routing.cvrp.alns_cvrp.repair_operators import (
        best_insertion, regret_2_position, regret_2_trip, regret_2_vehicle, 
        regret_3_position, regret_3_trip, regret_3_vehicle, 
        regret_4_position, regret_4_trip, regret_4_vehicle
    )
    
    # Import Utils (C√°c h√†m m·ªõi s·ª≠a)
    from routing.cvrp.alns_cvrp.utils import (
        optimize_all_start_times, 
        update_history_matrix, 
        cleanup_inter_factory_routes
    )
    
    print("‚úÖ [Env] ƒê√£ import th√†nh c√¥ng c√°c module ALNS!")

except ImportError as e:
    print(f"‚ùå [Env] L·ªñI IMPORT NGHI√äM TR·ªåNG: {e}")
    print(f"Current Sys Path: {sys.path}")
    # Re-raise ƒë·ªÉ d·ª´ng ch∆∞∆°ng tr√¨nh ngay, kh√¥ng d√πng dummy class n·ªØa (v√¨ dummy s·∫Ω l√†m train sai)
    raise e
def get_op_name(op):
    """
    T·ª± ƒë·ªông nh·∫≠n di·ªán tham s·ªë c·ªßa Partial ƒë·ªÉ in ra t√™n c·ª• th·ªÉ.
    V√≠ d·ª•: regret_k_insertion(k=2, mode='trip') -> regret_2_trip
    """
    # 1. N·∫øu h√†m c√≥ t√™n ch√≠nh ch·ªß (H√†m th∆∞·ªùng)
    if hasattr(op, '__name__'):
        return op.__name__

    # 2. N·∫øu l√† Partial (Bi·∫øn th·ªÉ d√πng functools.partial)
    if hasattr(op, 'func'):
        base_name = op.func.__name__
        kwargs = op.keywords if op.keywords else {}

        # --- T·ª∞ ƒê·ªòNG ƒê·∫∂T T√äN CHO REGRET ---
        if base_name == 'regret_k_insertion':
            k = kwargs.get('k_regret', '?')
            mode = kwargs.get('mode', 'position') # M·∫∑c ƒë·ªãnh l√† position
            return f"regret_{k}_{mode}"

        # --- T·ª∞ ƒê·ªòNG ƒê·∫∂T T√äN CHO WORST REMOVAL ---
        if base_name == 'worst_removal':
            alpha = kwargs.get('alpha', None)
            if alpha == 0: return "worst_removal_alpha_0"
            if alpha is not None and alpha > 100: return "worst_removal_bigM"
            return "worst_removal_adaptive"

        # --- T·ª∞ ƒê·ªòNG ƒê·∫∂T T√äN CHO SHAW ---
        if base_name == 'shaw_removal':
            w_dist = kwargs.get('w_dist', 0)
            w_tw = kwargs.get('w_tw', 0)
            w_depot = kwargs.get('w_depot', 0)
            w_access = kwargs.get('w_access', 0)
            
            if w_dist == 1.0 and w_tw == 0: return "shaw_spatial"
            if w_tw == 1.0: return "shaw_temporal"
            if w_depot > 0 and w_access > 0: return "shaw_structural"
            if w_dist == 1.0 and w_tw == 0.5: return "shaw_hybrid"

        return f"{base_name}_partial"

    return str(op)
# ==============================================================================
# L·ªöP GP_Matching (GI·ªÆ NGUY√äN C·ª¶A B·∫†N)
# ==============================================================================
# ==============================================================================
# L·ªöP GP_Matching (PHI√äN B·∫¢N DOUBLE PERMUTATION - ƒê√É FIX L·ªñI SELECT)
# ==============================================================================
class GP_Matching: 
    def __init__(self, destroy_ops, repair_ops, fitness_fn, current_solution, ngen=10, pop_size=10):
        if len(destroy_ops) != len(repair_ops):
            raise ValueError("S·ªë l∆∞·ª£ng to√°n t·ª≠ Destroy v√† Repair ph·∫£i b·∫±ng nhau")
            
        self.destroy_ops = destroy_ops 
        self.repair_ops = repair_ops
        self.num_pairs = len(destroy_ops)
        
        self.base_solution = current_solution
        self.fitness_fn = fitness_fn
        self.ngen = ngen
        self.pop_size = pop_size

        # --- Setup DEAP ---
        if not hasattr(creator, "FitnessMin"): 
            creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
        if not hasattr(creator, "Individual"):
            creator.create("Individual", list, fitness=creator.FitnessMin)

        self.toolbox = base.Toolbox()

        # 1. KH·ªûI T·∫†O C√Å TH·ªÇ
        def init_double_permutation(icls, size):
            perm1 = random.sample(range(size), size) # Ho√°n v·ªã cho Destroy
            perm2 = random.sample(range(size), size) # Ho√°n v·ªã cho Repair
            return icls(perm1 + perm2)

        self.toolbox.register("individual", init_double_permutation, creator.Individual, self.num_pairs)
        self.toolbox.register("population", tools.initRepeat, list, self.toolbox.individual)

        # 2. H√ÄM LAI GH√âP (MATE)
        def cxTwoPartOrdered(ind1, ind2):
            size = len(ind1) // 2
            tools.cxOrdered(ind1[:size], ind2[:size])
            tools.cxOrdered(ind1[size:], ind2[size:])
            return ind1, ind2

        self.toolbox.register("mate", cxTwoPartOrdered)

        # 3. H√ÄM ƒê·ªòT BI·∫æN (MUTATE)
        def mutTwoPartShuffle(ind, indpb):
            size = len(ind) // 2
            tools.mutShuffleIndexes(ind[:size], indpb)
            tools.mutShuffleIndexes(ind[size:], indpb)
            return ind,

        self.toolbox.register("mutate", mutTwoPartShuffle, indpb=0.3)

        # 4. H√ÄM CH·ªåN L·ªåC (SELECT) - [ƒê√É B·ªî SUNG ƒê·ªÇ S·ª¨A L·ªñI]
        # S·ª≠ d·ª•ng Tournament Selection (Ch·ªçn l·ªçc c·∫°nh tranh)
        self.toolbox.register("select", tools.selTournament, tournsize=3)
        
        # 5. H√ÄM ƒê√ÅNH GI√Å (EVALUATE)
        def eval_func(individual):
            sequence = []
            d_indices = individual[:self.num_pairs] 
            r_indices = individual[self.num_pairs:] 
            
            for i in range(self.num_pairs):
                d_op = self.destroy_ops[d_indices[i]]
                r_op = self.repair_ops[r_indices[i]]
                sequence.append((d_op, r_op))
            
            temp_solution_for_eval = copy.deepcopy(self.base_solution)
            return (self.fitness_fn(sequence, temp_solution_for_eval),)
        
        self.toolbox.register("evaluate", eval_func)

    def run(self):
        pop = self.toolbox.population(n=self.pop_size)
        
        # Ch·∫°y thu·∫≠t to√°n di truy·ªÅn
        # L∆∞u √Ω: ƒê·∫£m b·∫£o ƒë√£ import algorithms ·ªü ƒë·∫ßu file: from deap import algorithms
        final_pop = algorithms.eaSimple(pop, self.toolbox, cxpb=0.7, mutpb=0.2, 
                                        ngen=self.ngen, verbose=False)
        
        best_ind = tools.selBest(pop, 1)[0]
        
        best_seq = []
        d_indices = best_ind[:self.num_pairs]
        r_indices = best_ind[self.num_pairs:]
        
        for i in range(self.num_pairs):
            d_op = self.destroy_ops[d_indices[i]]
            r_op = self.repair_ops[r_indices[i]]
            best_seq.append((d_op, r_op))
            
        return best_seq

# ==============================================================================
# M√îI TR∆Ø·ªúNG PPO T√çCH H·ª¢P GP (ƒê√É S·ª¨A ƒê·ªîI)
# ==============================================================================
class PPO_ALNS_Env_GP(gym.Env):
    def __init__(self, problem_instance, max_iterations = 125, buffer_size=4, **kwargs):
        super(PPO_ALNS_Env_GP, self).__init__()
        
        self.problem_instance = problem_instance
        self.random_state = np.random.RandomState()
        
        # Import c√°c operators
        self.destroy_operators = [random_removal, worst_removal_alpha_0, worst_removal_bigM, worst_removal_adaptive, time_worst_removal, shaw_spatial, shaw_hybrid, shaw_temporal, shaw_structural, trip_removal, historical_removal]
        self.repair_operators = [best_insertion, regret_2_position, regret_2_trip, regret_2_vehicle, regret_3_position, regret_3_trip, regret_3_vehicle, regret_4_position, regret_4_trip, regret_4_vehicle]
        
        self.action_space = spaces.MultiDiscrete([len(self.destroy_operators), len(self.repair_operators)])
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(9,), dtype=np.float32)

        self.max_iterations = max_iterations 
        self.buffer_size = buffer_size
        self.destroy_buffer = []
        self.repair_buffer = []

        # C√°c bi·∫øn theo d√µi
        self.current_solution = None
        self.initial_solution = None
        self.best_solution = None
        self.initial_objective = float('inf')
        self.best_objective = float('inf')
        self.stag_count = 0
        self.current_iteration = 0
        self.start_temperature = kwargs.get('start_temperature', 1)
        
        self.history_matrix = {}
        
        # [M·ªöI] Bi·∫øn ƒë·∫øm s·ªë l·∫ßn li√™n ti·∫øp kh√¥ng t√¨m th·∫•y l·ªùi gi·∫£i feasible
        self.infeasible_counter = 0

    # [M·ªöI] H√ÄM C·∫§P C·ª®U
    # Nh·ªõ import ·ªü ƒë·∫ßu file environment
# from routing.cvrp.alns_cvrp.destroy_operators import infeasible_constraint_removal

    def _sanitize_and_repair(self, solution):
        """
        H√†m c·∫•p c·ª©u: R√† so√°t v√† s·ª≠a c√°c vi ph·∫°m c·ª©ng (Capacity & Overlap).
        """
        print("üö® [Emergency] Triggering Sanitize and Repair (Hard Constraints)...")
        
        # 1. D·ªçn d·∫πp c·∫•u tr√∫c
        sol = cleanup_inter_factory_routes(solution)
        
        # 2. G·ªåI TO√ÅN T·ª¨ INFEASIBLE REMOVAL
        # Fraction n√™n ƒë·ªÉ kho·∫£ng 0.2 - 0.3 ƒë·ªÉ ƒë·ªß r·ªông cho vi·ªác s·∫Øp x·∫øp l·∫°i
        destroy_op = infeasible_constraint_removal
        op_kwargs = {'remove_fraction': 0.25} 
        
        # Logic destroy tr·∫£ v·ªÅ (new_sol, list_removed_ids)
        destroyed, unvisited = destroy_op(sol, self.random_state, **op_kwargs)
        
        # N·∫øu kh√¥ng c√≥ g√¨ b·ªã x√≥a -> Nghƒ©a l√† kh√¥ng c√≥ vi ph·∫°m Overlap/Capacity
        if not unvisited:
            print("   -> Solution is feasible (checking Hard Constraints). No repair needed.")
            return sol

        print(f"   -> Detected Hard Violations. Removed {len(unvisited)} customers.")
        destroyed = update_solution_state_after_destroy(destroyed)
        
        # 3. Ch√®n l·∫°i an to√†n b·∫±ng Regret-3-Trip
        # Regret-3-Trip r·∫•t m·∫°nh trong vi·ªác t√¨m khe h·ªü cho Multi-trip
        if unvisited:
            farms = [c for c in unvisited if not str(c).startswith('TRANSFER_')]
            if farms:
                # Regret 3 Trip (Mode trip quan tr·ªçng cho Multi-trip)
                repaired, _ = regret_3_trip(destroyed, self.random_state, unvisited_customers=farms)
                return repaired
                
        return destroyed

    def _execute_operator_sequence(self, sequence, solution_to_mod):
        current_temp = solution_to_mod
        progress = self.current_iteration / self.max_iterations
        
        base_remove = 0.15 if len(sequence) >= 2 else 0.2
        MAX_REMOVE = base_remove
        MIN_REMOVE = 0.05
        remove_fraction = MAX_REMOVE - (MAX_REMOVE - MIN_REMOVE) * progress
        
        op_kwargs = {
            'remove_fraction': remove_fraction,
            'history_matrix': self.history_matrix
        }

        for i, (destroy_op, repair_op) in enumerate(sequence):
            current_temp = cleanup_inter_factory_routes(current_temp)
            destroyed, unvisited = destroy_op(current_temp, self.random_state, **op_kwargs)
            destroyed = update_solution_state_after_destroy(destroyed)
            
            if unvisited:
                farms_only = [c for c in unvisited if not str(c).startswith('TRANSFER_')]
                if farms_only:
                    repaired, _ = repair_op(destroyed, self.random_state, unvisited_customers=farms_only)
                    current_temp = repaired
                else:
                    current_temp = destroyed
            else:
                current_temp = destroyed
            
        return current_temp

    def _fitness_function_for_gp(self, sequence, temp_solution):
        final_sol = self._execute_operator_sequence(sequence, temp_solution)
        return final_sol.objective()[0]

    def reset(self):
        print(">>> M√¥i tr∆∞·ªùng PPO ƒë∆∞·ª£c reset...")
        initial_schedule = compute_initial_solution(self.problem_instance, self.random_state)
        self.initial_solution = cvrpEnv(initial_schedule, self.problem_instance, seed=None)
        
        self.initial_solution = cleanup_inter_factory_routes(self.initial_solution)
        
        self.current_solution = copy.deepcopy(self.initial_solution)
        self.best_solution = copy.deepcopy(self.initial_solution)
        
        self.history_matrix = {}
        update_history_matrix(self.history_matrix, self.current_solution)
        
        initial_results = self.initial_solution.objective()
        self.initial_objective = initial_results[0]
        self.best_objective = initial_results[0]
        
        self.best_time_penalty = initial_results[1]
        self.best_wait_time = initial_results[2]
        self.best_capacity_penalty = initial_results[3]

        self.stag_count = 0
        self.current_iteration = 0
        self.destroy_buffer = []
        self.repair_buffer = []
        
        # [M·ªöI] Reset counter infeasible
        self.infeasible_counter = 0
        
        return self._get_state()

    def _get_state(self):
        current_metrics = self.current_solution.objective()
        current_obj, time_penalty, wait_time, cap_penalty = current_metrics[:4]
        epsilon = 1e-6

        state = np.array([
            (current_obj - self.best_objective) / (self.best_objective + epsilon),
            self.stag_count / ((self.max_iterations / 10) + epsilon),
            self.current_iteration / self.max_iterations,
            (self.start_temperature * (0.999 ** (self.current_iteration * self.buffer_size))) / self.start_temperature,
            current_obj / (self.initial_objective + epsilon),
            time_penalty / (current_obj + epsilon),
            cap_penalty / (current_obj + epsilon),
            wait_time / (current_obj + epsilon),
            len(self.current_solution.schedule) / (len(self.initial_solution.schedule) + epsilon)
        ], dtype=np.float32)
        
        return state

    def step(self, action):
        destroy_idx, repair_idx = action
        
        destroy_op = self.destroy_operators[destroy_idx]
        repair_op = self.repair_operators[repair_idx]
        
        self.destroy_buffer.append(destroy_op)
        self.repair_buffer.append(repair_op)

        # --- TR∆Ø·ªúNG H·ª¢P 1: BUFFER CH∆ØA ƒê·∫¶Y ---
        if len(self.destroy_buffer) < self.buffer_size:
            done = self.current_iteration >= self.max_iterations
            return self._get_state(), 0, done, False, {'best_objective': self.best_objective}

        # --- TR∆Ø·ªúNG H·ª¢P 2: BUFFER ƒê·∫¶Y ---
        self.current_iteration += 1
        
        print(f"\n--- Buffer ƒë·∫ßy (Size {self.buffer_size}). Iter {self.current_iteration}. Th·ª±c thi Sequence... ---")

        best_sequence = list(zip(self.destroy_buffer, self.repair_buffer))

        print(f"üíé Direct Sequence Execution:")
        for i, (d_op, r_op) in enumerate(best_sequence, 1):
            print(f"   Step {i}: [{get_op_name(d_op)}] -> [{get_op_name(r_op)}]")

        # B. Th·ª±c thi chu·ªói
        objective_before = self.current_solution.objective()[0]
        
        new_solution = copy.deepcopy(self.current_solution)
        new_solution = self._execute_operator_sequence(best_sequence, new_solution)
        new_solution = optimize_all_start_times(new_solution)
        
        update_history_matrix(self.history_matrix, new_solution)

        # ======================================================================
        # [M·ªöI] KI·ªÇM TRA FEASIBLE V√Ä K√çCH HO·∫†T S·ª¨A CH·ªÆA
        # ======================================================================
# ======================================================================
        # [M·ªöI] KI·ªÇM TRA FEASIBLE (ƒê√£ v√° l·ªói Logic "V·ª©t kh√°ch")
        # ======================================================================
        metrics_temp = new_solution.objective()
        temp_time_pen = metrics_temp[1]
        temp_cap_pen = metrics_temp[3]
        current_obj = metrics_temp[0] # L·∫•y t·ªïng objective hi·ªán t·∫°i
        
        # Ng∆∞·ª°ng an to√†n: N·∫øu Objective > 1.000.000 nghƒ©a l√† ch·∫Øc ch·∫Øn c√≥ Penalty 
        # (d√π l√† Time, Cap hay Dropped Customer)
        PENALTY_THRESHOLD = 1_000_000 
        
        # ƒêi·ªÅu ki·ªán Feasible ch·∫∑t ch·∫Ω h∆°n:
        # 1. Kh√¥ng vi ph·∫°m Time
        # 2. Kh√¥ng vi ph·∫°m Capacity
        # 3. T·ªïng chi ph√≠ ph·∫£i h·ª£p l√Ω (nghƒ©a l√† kh√¥ng b·ªã ph·∫°t Dropped Customer)
        if temp_time_pen == 0 and temp_cap_pen == 0 and current_obj < PENALTY_THRESHOLD:
            self.infeasible_counter = 0
        else:
            self.infeasible_counter += 1
            print(f"‚ö†Ô∏è Infeasible count: {self.infeasible_counter}/10 (Obj: {current_obj:.0f})")

        # K√≠ch ho·∫°t s·ª≠a ch·ªØa
        if self.infeasible_counter >= 10:
            new_solution = self._sanitize_and_repair(new_solution)
            new_solution = optimize_all_start_times(new_solution)
            
            # Sau khi s·ª≠a xong th√¨ b·∫Øt bu·ªôc reset
            self.infeasible_counter = 0

        # K√≠ch ho·∫°t s·ª≠a ch·ªØa n·∫øu qu√° 10 l·∫ßn infeasible
        if self.infeasible_counter >= 10:
            new_solution = self._sanitize_and_repair(new_solution)
            new_solution = optimize_all_start_times(new_solution) # T·ªëi ∆∞u l·∫°i time sau khi s·ª≠a
            self.infeasible_counter = 0 # Reset counter sau khi s·ª≠a
        
        # C. T√≠nh to√°n k·∫øt qu·∫£ (L·∫•y l·∫°i objective sau khi c√≥ th·ªÉ ƒë√£ s·ª≠a)
        final_results = new_solution.objective()
        objective_after = final_results[0]
        print("New_objective: ", objective_after)

        # D. T√≠nh Reward
        improvement = (objective_before - objective_after) / (objective_before + 1e-6)
        reward = improvement * 10 
        
        # ======================================================================
        # E. C∆† CH·∫æ CH·∫§P NH·∫¨N
        # ======================================================================
        accepted = False
        is_new_best = False

        if objective_after < objective_before:
            accepted = True
        else:
            progress = self.current_iteration / self.max_iterations
            current_temp = (self.initial_objective * 0.05) * (1 - progress)
            current_temp = max(current_temp, 1e-6) 
            
            diff = objective_after - objective_before
            
            if diff > self.initial_objective * 0.5:
                probability = 0
            else:
                probability = math.exp(-diff / current_temp)
            
            if self.random_state.rand() < probability:
                accepted = True
            else:
                accepted = False

        # ======================================================================
        # F. C·∫¨P NH·∫¨T TR·∫†NG TH√ÅI
        # ======================================================================
        if accepted:
            self.current_solution = new_solution
            
            if objective_after < self.best_objective:
                self.best_objective = objective_after
                self.best_solution = copy.deepcopy(new_solution)
                is_new_best = True
                
                self.best_time_penalty = final_results[1]
                self.best_wait_time = final_results[2]
                self.best_capacity_penalty = final_results[3]
                
                print(f"üéâ New Best: {self.best_objective:.2f}")

        # G. Tinh ch·ªânh Reward
        if is_new_best:
            self.stag_count = 0
            reward += 20.0 
        else:
            self.stag_count += 1
            if not accepted:
                reward -= 0.5
            elif improvement <= 0:
                reward -= 0.1

        # H. D·ªçn d·∫πp & Return
        self.destroy_buffer = [] 
        self.repair_buffer = [] 

        done = self.current_iteration >= self.max_iterations
        next_state = self._get_state()
        info = {
            'best_objective': self.best_objective,
            'accepted': accepted
        }

        return next_state, reward, done, False, info